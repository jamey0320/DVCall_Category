{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1630340194010,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "sj6-rCfAx8TB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import urllib.request\n",
    "import json\n",
    "import pickle\n",
    "from eunjeon import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2472,
     "status": "ok",
     "timestamp": 1630340198330,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "uzAQNCftx8TC",
    "outputId": "67ff91d1-0463-4090-8ba1-fff96b4ceedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 대화 개수 : 314996\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/full.csv\")\n",
    "\n",
    "data = data.drop(['summary'], axis=1)\n",
    "data.drop_duplicates(subset=['utterance'], inplace=True)\n",
    "print('전체 대화 개수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1630340205003,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "lf7oJhbHx8TF"
   },
   "outputs": [],
   "source": [
    "# 전처리 함수 (필요없는 문자 제거, 형태소 분석 및 분리)\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r'\\#[^)]*\\#', '', sentence) # 마스킹된 데이터(이름, 날짜 등) 제거\n",
    "    sentence = re.sub(\"[^가-힣]\", \" \", sentence) # ㅋㅋㅋ, 영어, 특수문자, 숫자 등 제거\n",
    "    \n",
    "    speech_pos = mecab.pos(sentence)\n",
    "    #조사, 어미, 접두접미사 등 제거\n",
    "    clear_pos = [n for n, tag in speech_pos if tag.startswith('M') | tag.startswith('N') | tag.startswith('V')]\n",
    "    sentence = ' '.join(clear_pos)\n",
    "    \n",
    "    tokens = ' '.join(word for word in sentence.split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 77693,
     "status": "ok",
     "timestamp": 1630340283878,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "N4XQYcixx8TG"
   },
   "outputs": [],
   "source": [
    "# utterance(대화 본문) 전처리\n",
    "clean_text = []\n",
    "\n",
    "for s in data['utterance']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "data['utterance'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1630340301241,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "OH_4qoelx8TH",
    "outputId": "e5af6621-9075-470f-cfab-cc591fb66973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 대화 개수 : 314324\n"
     ]
    }
   ],
   "source": [
    "# 길이가 공백인 샘플은 NULL 값으로 변환 후 제거 (전처리 과정에서 모든 단어 삭제된 케이스)\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 대화 개수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1630340312523,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "x9bpm6M3x8TH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.0\n"
     ]
    }
   ],
   "source": [
    "# 대화 파트 길이 측정\n",
    "text_len = [len(s.split()) for s in data['utterance']]\n",
    "print(np.percentile(text_len, 75) * 1.5) #maximum\n",
    "\n",
    "# 패딩길이\n",
    "text_max_len = 63 # Q3 * 1.5\n",
    "summary_max_len = 4 # 카테고리 최대 단어 갯수 + 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1263,
     "status": "ok",
     "timestamp": 1630340324880,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "DqXxqkDCx8TH",
    "outputId": "130e53d9-b346-464d-af83-43aa37d6fff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 298121\n"
     ]
    }
   ],
   "source": [
    "# 패딩 길이보다 본문이 긴 데이터는 사용하지 않음\n",
    "data = data[data['utterance'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1630340326305,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "F_Y2yHasx8TH",
    "outputId": "44bb9744-f7cc-40e0-e316-69c79a6e6ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>topic</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>마져 난 그래서 한 번 보 엄청 오래 보 친구 많 스탈 아냐 딱 보이 좁 깊 사귀 ...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "      <td>sostoken 개인 및 관계</td>\n",
       "      <td>개인 및 관계 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내일 아침 먹 시 일어나 하 가능 피곤 하 그래도 먹 했 최대한 일어나 챙겨 먹 보...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "      <td>sostoken 개인 및 관계</td>\n",
       "      <td>개인 및 관계 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이따가 저 못 할 수 잇 나 역내 저 해두 댕 왜 못 행 아빠 계시 나 저 하 아빠...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "      <td>sostoken 개인 및 관계</td>\n",
       "      <td>개인 및 관계 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>상금 천만 원 번 선택 사람 빵 글 쿠만 얼마 오려 얼마 안 나올 듯 육처 넌 너 ...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "      <td>sostoken 개인 및 관계</td>\n",
       "      <td>개인 및 관계 eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아까 둘 이 동시 울 약간 멘탈 후 달림 지금 막 수 시간 남 그거 먹이 재우 해 ...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "      <td>sostoken 개인 및 관계</td>\n",
       "      <td>개인 및 관계 eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance    topic  \\\n",
       "0  마져 난 그래서 한 번 보 엄청 오래 보 친구 많 스탈 아냐 딱 보이 좁 깊 사귀 ...  개인 및 관계   \n",
       "1  내일 아침 먹 시 일어나 하 가능 피곤 하 그래도 먹 했 최대한 일어나 챙겨 먹 보...  개인 및 관계   \n",
       "2  이따가 저 못 할 수 잇 나 역내 저 해두 댕 왜 못 행 아빠 계시 나 저 하 아빠...  개인 및 관계   \n",
       "3  상금 천만 원 번 선택 사람 빵 글 쿠만 얼마 오려 얼마 안 나올 듯 육처 넌 너 ...  개인 및 관계   \n",
       "4  아까 둘 이 동시 울 약간 멘탈 후 달림 지금 막 수 시간 남 그거 먹이 재우 해 ...  개인 및 관계   \n",
       "\n",
       "      decoder_input    decoder_target  \n",
       "0  sostoken 개인 및 관계  개인 및 관계 eostoken  \n",
       "1  sostoken 개인 및 관계  개인 및 관계 eostoken  \n",
       "2  sostoken 개인 및 관계  개인 및 관계 eostoken  \n",
       "3  sostoken 개인 및 관계  개인 및 관계 eostoken  \n",
       "4  sostoken 개인 및 관계  개인 및 관계 eostoken  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주제 파트에는 시작 토큰과 종료 토큰을 추가\n",
    "data['decoder_input'] = data['topic'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['topic'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1630340329154,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "OcmNsDFBx8TH"
   },
   "outputs": [],
   "source": [
    "# 학습 위해 데이터 랜덤 셔플한 뒤 학습, 테스트 데이터 스플릿\n",
    "encoder_input = np.array(data['utterance'])\n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1630340333466,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "4Df8GQrix8TI"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.15)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9309,
     "status": "ok",
     "timestamp": 1630340347329,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "qfAhAlozx8TI"
   },
   "outputs": [],
   "source": [
    "# 희귀 단어 통계를 위한 임시 토크나이저\n",
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1630340349036,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "-BRKjkPyx8TI",
    "outputId": "aa6cb7ee-4204-4651-fffc-590687bf6a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 76130\n",
      "희귀 단어를 제외시킬 경우의 단어 집합의 크기 16904\n",
      "희귀 단어의 비율: 77.79587547615921\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.0511399056988977\n"
     ]
    }
   ],
   "source": [
    "# 예측 시 overfitting 등 다양한 문제 야기할 수 있는 희귀 단어 제외를 위한 통계 체크\n",
    "threshold = 19\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18781,
     "status": "ok",
     "timestamp": 1630340372500,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "QI50RpM6x8TI"
   },
   "outputs": [],
   "source": [
    "# 전체 단어 중 약 3%를 차지하는 희귀 단어 제거\n",
    "# 단어 집합의 크기를 16900으로 제한하고 tokenizer를 pickle 파일로 저장\n",
    "src_vocab = 16900\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "with open('model/tokenizer1.pickle', 'wb') as s_handle:\n",
    "    pickle.dump(src_tokenizer, s_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4245,
     "status": "ok",
     "timestamp": 1630340384471,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "UIw1YOxmx8TJ"
   },
   "outputs": [],
   "source": [
    "# 단어 집합의 크기를 17으로 제한하고 (주제 파트는 사용 단어가 정해져있음) tokenizer를 pickle 파일로 저장\n",
    "tar_vocab = 17\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "with open('model/tokenizer2.pickle', 'wb') as t_handle:\n",
    "    pickle.dump(tar_tokenizer, t_handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1630340425522,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "L6SipkNYx8TJ"
   },
   "outputs": [],
   "source": [
    "# 주제 파트에서 토큰만 남은 (사실상 NULL값) 데이터 제거\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 4035,
     "status": "ok",
     "timestamp": 1630340436850,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "KgbMyjJdx8TK"
   },
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1630340445248,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "AF2jisUUx8TK",
    "outputId": "ce120445-5006-4e47-ee4a-b1b2b3bb32be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더 입력 층\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1630340450521,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "Igj4LrvAx8TK"
   },
   "outputs": [],
   "source": [
    "# 디코더 입력 층\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c]) # 인코더의 마지막 LSTM 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1630340453223,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "iHw6S5hYx8TK"
   },
   "outputs": [],
   "source": [
    "# 어텐션 층 임포트\n",
    "import ssl\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1630340458727,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "mAJZDVXox8TK",
    "outputId": "c519b951-f90e-4090-bb4a-e02b3af7e569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 63, 128)      2163200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 63, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 63, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    2176        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 63, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 17)     8721        concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,144,529\n",
      "Trainable params: 4,144,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션 층의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1630340462715,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "WRjB3_z0x8TK"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1313016,
     "status": "ok",
     "timestamp": 1630341779457,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "Nz6xq-i1x8TK",
    "outputId": "3b2e3d12-2ec7-4723-8a3e-f82289321ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 240535 samples, validate on 42456 samples\n",
      "Epoch 1/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.4319\n",
      "Epoch 00001: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 363s 2ms/sample - loss: 0.4318 - val_loss: 0.2690\n",
      "Epoch 2/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2523\n",
      "Epoch 00002: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 359s 1ms/sample - loss: 0.2523 - val_loss: 0.2366\n",
      "Epoch 3/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2314\n",
      "Epoch 00003: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 346s 1ms/sample - loss: 0.2314 - val_loss: 0.2308\n",
      "Epoch 4/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2220\n",
      "Epoch 00004: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 342s 1ms/sample - loss: 0.2220 - val_loss: 0.2300\n",
      "Epoch 5/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2158\n",
      "Epoch 00005: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 341s 1ms/sample - loss: 0.2158 - val_loss: 0.2243\n",
      "Epoch 6/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2111\n",
      "Epoch 00006: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 344s 1ms/sample - loss: 0.2111 - val_loss: 0.2231\n",
      "Epoch 7/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2068\n",
      "Epoch 00007: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 346s 1ms/sample - loss: 0.2067 - val_loss: 0.2226\n",
      "Epoch 8/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.2031\n",
      "Epoch 00008: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 344s 1ms/sample - loss: 0.2031 - val_loss: 0.2206\n",
      "Epoch 9/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.1998\n",
      "Epoch 00009: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 340s 1ms/sample - loss: 0.1998 - val_loss: 0.2208\n",
      "Epoch 10/15\n",
      "240384/240535 [============================>.] - ETA: 0s - loss: 0.1967\n",
      "Epoch 00010: saving model to check.ckpt\n",
      "240535/240535 [==============================] - 343s 1ms/sample - loss: 0.1966 - val_loss: 0.2234\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"model/check.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es, cp_callback], epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 모델(카테고리 추출 모델) 저장\n",
    "model.save('model/model_cat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1630341793534,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "kT72jRYjx8TL"
   },
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1630341794507,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "8QlZEZ9Xx8TL"
   },
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 모델 저장\n",
    "encoder_model.save('model/model_en.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1506,
     "status": "ok",
     "timestamp": 1630341797159,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "Os2ltQ-Nx8TL"
   },
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1630341798951,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "yaQdY9I6x8TL"
   },
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 모델 저장\n",
    "decoder_model.save('model/model_de.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1630341801039,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "Y2nFNduqx8TL"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1630341803620,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "GKXmHqt0x8TL"
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 대화 데이터로 실험\n",
    "pp_text=[]\n",
    "fin_text=[]\n",
    "k=0\n",
    "\n",
    "f = open(\"data/testone.txt\", 'r')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    pp_text.append(preprocess_sentence(line))\n",
    "f.close()\n",
    "tkn_text = src_tokenizer.texts_to_sequences(pp_text)\n",
    "\n",
    "for i in range(len(tkn_text)):\n",
    "        if not tkn_text[i-k]:\n",
    "            del tkn_text[i-k]\n",
    "            k+=1\n",
    "        else:\n",
    "            fin_text.append(np.array(tkn_text[i-k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1630341809438,
     "user": {
      "displayName": "류정욱",
      "photoUrl": "",
      "userId": "00002964864695703593"
     },
     "user_tz": -540
    },
    "id": "_XKwN7OOx8TM"
   },
   "outputs": [],
   "source": [
    "fin_text = pad_sequences(fin_text, maxlen = text_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 별로 주제 추출, 대화 속 가장 많이 나온 주제로 대화 주제 선정\n",
    "cat_list = [\" 개인 및 관계\", \" 미용과 건강\", \" 상거래 쇼핑\", \" 시사교육\", \" 식음료\", \" 여가 생활\", \" 일과 직업\", \" 주거와 생활\", \" 행사\"]\n",
    "\n",
    "def pick_cat(input_text):\n",
    "    fir_list=[]\n",
    "    for i in range(len(input_text)):\n",
    "        fir_list.append(decode_sequence(input_text[i].reshape(1, text_max_len)))\n",
    "    \n",
    "    cat_count=[]\n",
    "    for i in range(len(cat_list)):\n",
    "        cat_count.append(fir_list.count(cat_list[i]))\n",
    "        \n",
    "    max_count = max(cat_count)\n",
    "    max_name = cat_list[cat_count.index(max(cat_count))]\n",
    "\n",
    "    cat_count[cat_count.index(max(cat_count))] = 0\n",
    "\n",
    "    max2_count = max(cat_count)\n",
    "    max2_name = cat_list[cat_count.index(max(cat_count))]\n",
    "\n",
    "    cat_count[cat_count.index(max(cat_count))] = 0\n",
    "    \n",
    "    if max_name == \" 개인 및 관계\":\n",
    "        if max_count >= max2_count*1.5:\n",
    "            cat_result = max_name\n",
    "        else:\n",
    "            cat_result = max2_name\n",
    "    else:\n",
    "        cat_result = max_name\n",
    "    \n",
    "    return cat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 개인 및 관계'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_cat(fin_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "카테고리 추출 모델 ver2 수정중.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
